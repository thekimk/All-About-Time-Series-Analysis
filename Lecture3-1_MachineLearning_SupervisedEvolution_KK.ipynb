{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **알고리즘의 발전방향**\n",
    "\n",
    "[![Open in Colab](http://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thekimk/All-About-Machine-Learning/blob/main/Lecture3-1_MachineLearning_SupervisedEvolution_KK.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## 통계추론에서 기계학습/딥러닝학습으로\n",
    "\n",
    "> **\"데이터 과학은 크게 `2가지 관점`으로 발전\"**\n",
    "> - **통계학(Inferential Statistics):**\n",
    ">> - 데이터 과학의 근간\n",
    ">> - `통계학 기반의 다양한 기능들`은 딥러닝, 패턴인식, 기계학습 등에서 사용중\n",
    "> - **컴퓨터공학(Computer Science):**\n",
    ">> - `부품 가격 절하와 성능 향상`은 분석 성능에 영향\n",
    ">> - `통계학에 컴퓨터 공학적인 접근`을 받아들이게 하고, `통계와 기계학습 영역이 겹합되어 시너지`를 이루게 됨\n",
    "\n",
    "---\n",
    "\n",
    "- **통계학습(Statistical Learning) vs 기계학습(Machine Learning):** 알고리즘 생성 방식\n",
    "\n",
    "<center><img src='Image/Expert/StatisticsMachinelearning.png' width='800'>(루이, 다빈치랩스)</center>\n",
    "\n",
    "> **\"데이터를 통해 문제 해결한다는 점은 일맥상통하나, 해결하는 `목표/전략/방식에 대한 출발점이 다르며` 점차 `경계가 모호`해지고 있음\"**\n",
    "\n",
    "|  | **통계학습(Statistical Learning)** | **기계학습(Machine Learning)** |\n",
    "|:---:|:---:|:---:|\n",
    "| **이론적 배경** | `통계학` | `컴퓨터과학` |\n",
    "| **발전 기반** | 통계학, 수치해석 등 | 패턴인식, 인공지능 등 |\n",
    "| **모형 구조** | 대부분 `화이트박스` | 대부분 `블랙박스` |\n",
    "| **관심 목적** | `설명력`, `실패위험` 줄이기 | `정확성`, `성공확률` 높이기 |\n",
    "| **주 사용 데이터** | 관측치 및 변수가 적은 경우 | 관측치 및 변수가 많은 경우 |\n",
    "| **상황/가정 반영** | 의존적<br>(독립성, 정규성, 등분산성 등) | 독립적<br>(대부분 무시) |\n",
    "| **학습 방법** | 데이터에 맞게 `최적화 중점` | `반복학습으로 모델 구축` 중점 |\n",
    "| **성능 평가** | 데이터의 해석과 가정 적합성 등 | 분할 데이터 반복 평가 |\n",
    "| **특징** | 가설(Hypothesis), 모집단(Population), 표분(Sample)에 기반하여 <br>데이터를 기술(Descriptive)하거나 추론(Inference)하는데 이용 | 예측력(Prediction) 중심의 다양한 문제 해결을 위한 <br> 지도(Supervised), 비지도(Unsupervised), 강화학습(Reinforcement) 등의 방법론 구축에 이용 |\n",
    "| **문제 예시** | 대기오염과 호흡기 질환의 관계 <br> 배너위치에 따른 컨텐츠 클릭 빈도 변화 <br> 신규 장비의 불량률 감소 효과 분석 <br> 임상을 통한 신약의 효능 분석 | 이미지 데이터의 객체 구분 <br> 상황이나 사물인식 성능 향상 <br> 음성인식을 통한 AI스피커 성능 향상 <br> MRI데이터 사용 암 환자 조기 진단 |\n",
    "\n",
    "<center><img src='Image/Expert/DL_AutoFE.PNG' width='600'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확성 vs. 설명력\n",
    "\n",
    "**1) 기계학습 활용 데이터분석의 현실:**\n",
    "\n",
    "> **\"(이상적으로) 머신러닝 알고리즘에 데이터를 `학습/적합/모델링` 한다는 건..\"**     \n",
    ">\n",
    "> (1) 사람/사물/시스템이 `어떻게 동작하는지 이해`의 과정    \n",
    "> (2) 사람/사물/시스템이 만들어내는 `데이터를 체계적으로 요약`하는 과정    \n",
    "> (3) 미래의 예측값과 실제값의 비교로 `사람/사물/시스템을 일반화`하는 과정    \n",
    "> (4) 일반화된 사람/사물/시스템으로 더욱 `효과적이고 체계적인 의사결정`하는 방법    \n",
    "\n",
    "> **\"(현실적으로) 많은 시간과 비용이 투입되지만, `우리 사회를 이해((1),(2),(3)) <<< 빠른 의사결정(4)`에 집중되어 효과는 글쎄..\"**\n",
    ">\n",
    "> - 사회를 이해하기 위한 `사회학/교육학/철학/경제학 등`의 학문은 `((1),(2),(3))에 집중`\n",
    "> - `경영과학/컴퓨터과학/산업공학 등`의 학문은 기술적인 자동화나 인공지능을 반영하는 `(4)에 집중`\n",
    "> - 학문적 출신(?)에 따라 `분석에 대한 관점 차이` 또는 `비즈니스 방향 차이`가 존재할 수 있음\n",
    ">\n",
    "> <center><img src='Image/Advanced/Programming_Multidisciplinary.png' width='500'></center>\n",
    "\n",
    "---\n",
    "\n",
    "**2) `정확성 vs. 설명력`은 모두 욕심낼 수 없는 반비례 관계:**\n",
    "- 대부분의 `기계학습 및 딥러닝 모델`은 이론적 기반이 없기 때문에 `1회성 추정을 반복`하는 알고리즘  \n",
    "- `통계추론`은 이론적 기반의 `결과의 범위(신뢰구간)와 설명력`을 제공하기에 `반복추정이 필요없는` 알고리즘\n",
    "\n",
    "<center><img src='Image/Advanced/Performance_Explanability.png' width='600'></center>\n",
    "\n",
    "- **설명력 최근 연구동향:**   \n",
    "> - [DARPA](https://bdtechtalks.com/2019/01/10/darpa-xai-explainable-artificial-intelligence/)\n",
    "> - [LIME](https://blog.fastforwardlabs.com/2017/09/01/LIME-for-couples.html) $\\rightarrow$ [SHAP](https://shap.readthedocs.io/en/latest/)  \n",
    "\n",
    "---\n",
    "\n",
    "**3) 반비례 관계 원인:** `회귀분석(통계학습) vs 딥러닝(기계학습)`\n",
    "\n",
    "- **회귀분석(통계학습):** 함수의 `선형성`을 추정하는 정확성 보다 `설명력에 집중`하는 알고리즘\n",
    "- **딥러닝(기계학습):** 함수의 `비선형성`을 추정하는 설명력 보다 `정확성에 집중`하는 알고리즘\n",
    "\n",
    "| -                            | **회귀분석**                                            | **딥러닝**                                   |\n",
    "|----------------------------- |:----------------------------------- |:----------------------------------- |\n",
    "| **모델특징**                 | -                                                       | -                                                      |\n",
    "| 분석목적                     | 선형성파악(설명가능)                                    | 비선형성파악(설명불가)                                 |\n",
    "| 이론적(수학적) 근거          | 존재                                                    | 미존재                                                 |\n",
    "| **분석단계 특징(전처리)**    | -                                                       | -                                                      |\n",
    "| 데이터 로딩                  | <span style=\"color:blue\">Panel Data</span>              | <span style=\"color:red\">다양(운이좋으면 Panel)</span>  |\n",
    "| 데이터 빈칸 채우기/삭제      | <span style=\"color:red\">분석필요</span>                 | <span style=\"color:red\">분석필요</span>                |\n",
    "| 데이터 컬럼 추가/삭제        | <span style=\"color:red\">분석필요+민감</span>            | <span style=\"color:red\">분석필요+덜민감</span>         |\n",
    "| 데이터 분리                  | <span style=\"color:blue\">Train/Validate/Test</span>     | <span style=\"color:blue\">Train/Validate/Test</span>    |\n",
    "| 데이터 스케일링              | <span style=\"color:red\">분석필요/미필요</span>          | <span style=\"color:red\">분석필요</span>                |\n",
    "| **분석단계 특징(모델링)**    | -                                                       | -                                                      |\n",
    "| 입력 확인 및 변환            | <span style=\"color:blue\">Panel Data</span>              | <span style=\"color:red\">다양(정해지지 않음)</span>     |\n",
    "| 데이터 모델연결              | <span style=\"color:blue\">자동화</span>                  | <span style=\"color:red\">반자동화</span>                |\n",
    "| 비용함수(Cost)               | <span style=\"color:blue\">최소제곱에러(MSE)</span>       | <span style=\"color:red\">다양</span>                    |\n",
    "| 추정함수(Optimizer)          | <span style=\"color:blue\">고정(미분1회 대체가능)</span>  | <span style=\"color:red\">다양(미분지속)</span>          |\n",
    "| **분석단계 특징(검증)**      | -                                                       | -                                                      |\n",
    "| 정확성지표                   | <span style=\"color:red\">다양</span>                     | <span style=\"color:red\">다양</span>                    |\n",
    "| 잔차진단활용                 | <span style=\"color:red\">가능(분석필요)</span>           | <span style=\"color:blue\">불가</span>                   |\n",
    "| **분석단계 특징(결과해석)**  | -                                                       | -                                                      |\n",
    "| 관계성 시각화/영향력 해석    | <span style=\"color:red\">가능(분석필요)</span>           | <span style=\"color:blue\">불가</span>                   |   \n",
    "\n",
    "---\n",
    "\n",
    "**4) 실무적으로 기계학습 알고리즘의 중요성:**\n",
    "\n",
    "> **\"`자동화`에 집중되어 `딥러닝 알고리즘`을 활용하면 적용 케이스가 적고 성능향상이 낮을 수 있으며, `문제해결`에 집중하면 가장 많은 활용되는 모델링은 `성능과 설명력`을 어느정도 확보한 `기계학습` 알고리즘\"**\n",
    "\n",
    "<center><img src='Image/Advanced/MachineLearning_Algorithms.png' width='1000'>(https://cloud.tencent.com/developer/article/1071285)</center>  \n",
    "\n",
    "> - 통계추론과 딥러닝 가운데쯤 위치한 `기계학습 알고리즘을 이해`하는 것이 중요!\n",
    "\n",
    "<center><img src='Image/Expert/Advanced_Algorithms.webp' width='900'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **알고리즘 발전 이해를 위한 비용함수 구조**\n",
    "\n",
    "**0) 지도학습 문제해결 비교:** `회귀분석 vs 분류분석`\n",
    "\n",
    "- **Comparison Summary:**\n",
    "\n",
    "| **구분** | **Linear Regression** | **Logistic Regression** |\n",
    "|:---:|:---:|:---:|\n",
    "| **문제 유형<br>(해결 방향)** | 회귀<br>(Regression) | 분류<br>(Classification) |\n",
    "| **모델 가정<br>(전문가 이상형)** | 직선<br>(Linear) | 곡선<br>(Sigmoid) |\n",
    "| **비용 함수<br>(평가 기준)** | 정답과 예측의 차이가 최소인 직선 선택<br>(MSE) | 각 라벨을 잘 맞춘 곡선 선택<br>(Entropy) |\n",
    "| **검증 지표<br>(평가 확대)** | 정답과 예측의 차이가 얼마나 최소인가?<br>(RMSE, MSPE, MAE, MAPE, MedAE, MedAPE 등) | 각 라벨을 얼마나 잘 맞췄나?<br>(Precision, Recall, F1-score, Accuracy, AUC, ROC 등) |\n",
    "\n",
    "- `데이터분석 단계`는 동일하지만 `비용함수나 검증지표 등`에서 차이\n",
    "\n",
    "| | **Regression** | **Classification** |\n",
    "|:-:|:-|:-|\n",
    "| **분석목적** | 수치 예측 | 라벨 예측 |\n",
    "| **분석단계** |  |  |\n",
    "| <span style=\"color:blue\">전처리</span> | 동일 | 동일 |\n",
    "| <span style=\"color:red\">Base 알고리즘</span> | Linear Regression | Logistic Regression |\n",
    "| <span style=\"color:blue\">특징</span> | 선형 | 선형 |\n",
    "| <span style=\"color:red\">비용함수</span> | $(Y - \\hat{Y})^2$ | $-\\hat{Y}log(Pr(\\hat{Y}))$ $-$ $(1-\\hat{Y})log(1-Pr(\\hat{Y}))$ |\n",
    "| <span style=\"color:red\">검증지표</span> | MSE<br>     MAE<br>     RMSE<br>     MAPE<br>     R^2<br>     F검정<br>     t검정<br>     Log-Likelihood<br>     AIC<br>     BIC | Log-Likelihood<br>     Confusion Matrix<br>     Accuracy<br>     Precision<br>     Recall<br>     F1-score<br>     Classification Report<br>     ROC<br>     AUC |\n",
    "| <span style=\"color:red\">잔차진단</span> | 정규분포<br>     등분산성<br>     자기상관 | - |\n",
    "| **Advanced 알고리즘** | - Linear regression<br>     - Polynomial regression<br>     - Stepwise regression<br>     - Ridge/Lasso/ElasticNet regression<br>     - Bayesian Linear regression<br>     - Quantile regression<br>     - Decision Tree regression<br>     - Random Forest regression<br>     - Support Vector regression | - Logistic Regression<br>     - Ordinal Regression<br>     - Cox Regression<br>     - Naïve Bayes<br>     - Stochastic Gradient Descent<br>     - K-Nearest Neighbours<br>     - Decision Tree<br>     - Random Forest<br>     - Support Vector Machine |\n",
    "\n",
    "---\n",
    "\n",
    "**1) 수학적 이해:** `비용함수(Cost Function)` = `편향(Bias)` + `분산(Variance)` + `에러(Error)`\n",
    "\n",
    "<center><img src='Image/Expert/Bias-Variance_Structure.PNG' width='500'></center>\n",
    "\n",
    "> - $F$: `정답` 알고리즘, $\\hat{F}$: `예측`을 위해 데이터를 `학습`한 알고리즘\n",
    "> \n",
    "> \\begin{align*}\n",
    "\\text{Real Y} && Y &= F(x) \\\\\n",
    "\\text{Estimated Y} && \\hat{Y} &= \\hat{F}(x) + \\epsilon, ~~~ \\epsilon \\sim N(0, \\sigma^2) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Cost Function} && MSE &= E\\Bigl[\\bigl(Y-\\hat{Y})^2 \\Bigr] \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x)-\\hat{F}(x)-\\epsilon\\bigr)^2 \\Bigr] \\\\\n",
    "&& &= E\\Bigl[\\bigl([F(x) - \\hat{F}(x)] - \\epsilon\\bigr)^2 \\Bigr] \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - \\hat{F}(x)\\bigr)^2 \\Bigr] - 2 \\bigl(F(x) - \\hat{F}(x)\\bigr) E(\\epsilon) + E(\\epsilon^2) \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - \\hat{F}(x)\\bigr)^2 \\Bigr] + \\sigma^2 \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - E\\bigl[\\hat{F}(x)\\bigr] + E\\bigl[\\hat{F}(x)\\bigr] - \\hat{F}(x)\\bigr)^2 \\Bigr] + \\sigma^2 \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - E\\bigl[\\hat{F}(x)\\bigr] \\bigr)^2 \\Bigr] + E\\Bigl[\\bigl(E\\bigl[\\hat{F}(x)\\bigr] - \\hat{F}(x)\\bigr] \\bigr)^2 \\Bigr] + \\sigma^2 \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - \\bar{F}(x) \\bigr)^2 \\Bigr] + E\\Bigl[\\bigl(\\bar{F}(x) - \\hat{F}(x)\\bigr] \\bigr)^2 \\Bigr] + \\sigma^2 \\\\\n",
    "&& &= \\text{Bias}^2 \\bigl( \\hat{F}(x) \\bigr) + \\text{Variance} \\bigl( \\hat{F}(x) \\bigr) + \\text{Irreducible Natural Error}\n",
    "\\end{align*}\n",
    "\n",
    "<span style=\"color:red\">$\\Rightarrow$ **\"`비용함수를 줄이려면` 제거하기 어려운 에러를 뺀 `편향`과 `분산`을 줄이는 것이 최선\"**</span>\n",
    "\n",
    "---\n",
    "\n",
    "**2) 비수학적 이해:** 직관적으로 `편향 + 분산`이 `모두 작은` 경우 `알고리즘 성능 Best`\n",
    "\n",
    "> **편향(Bias):** `여러번 측정`된 정확성의 `중심 통계량(점추정)` \n",
    ">\n",
    "> - 여러번 모델링을 통해 데이터를 반복 학습 및 추정했을 때, `예측값이 실제값에서 얼마나 떨어져있는지` 측정\n",
    "> - `데이터 패턴을 잘 반영`했는지 측정\n",
    ">\n",
    "> **분산(Variance):** `여러번 측정`된 정확성의 `변동 통계량(구간추정)`  \n",
    ">\n",
    "> - 여러번 모델링을 통해 데이터를 반복 학습 및 추정했을 때, 실제값과 상관없이 `예측값들이 퍼져있는 정도`\n",
    "> - <span style=\"color:red\">**실제값과 관계없이 `예측값들의 퍼진 정도`만 의미!**</span>\n",
    ">   \n",
    "> <center><img src='Image/Expert/Bias_Variance1.jpeg' width='400'>(붉은색: Target, 파란색: Predicted)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비용함수에서 편향-분산 상충관계\n",
    "\n",
    "**1) 과소적합(Under-fittng) vs. 과대적합(Over-fitting):** 알고리즘의 `복잡도가 증가`할수록 `Over-fitting` 가능성 증가\n",
    "\n",
    "<center><img src='Image/Expert/Underfitting_Overfitting.png' width='600'></center>\n",
    "\n",
    "<center><img src='Image/Expert/Underfitting_Overfitting.jpg' width='600'></center>\n",
    "\n",
    "|  | **Underfitting** | **Overfitting** |\n",
    "|:---:|:---:|:---:|\n",
    "| **알고리즘 복잡도** | 낮음 | 높음 |\n",
    "| **특징** | 데이터 패턴 일부만 학습 | 데이터 패턴 및 잡음/에러까지도 학습 |\n",
    "\n",
    "---\n",
    "\n",
    "**2) 알고리즘 복잡도와 예측 성능:**\n",
    "\n",
    "<center><img src='Image/Expert/Bias_Variance2.jpeg' width='400'>(붉은색: Target, 파란색: Predicted)</center>\n",
    "\n",
    "|  | **(1,1)** | **(2,1)** | **(1,2)** | **(2,2)** |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "| **학습정도** | 최적 | 과소 | 과대 | 과소 + 과대 |\n",
    "| **복잡도** | 데이터 대비 `적절` | 데이터 대비 `낮음` | 데이터 대비 `높음` | 일부 데이터 `낮음` + 나머지 데이터 `높음` |\n",
    "| **평균-분산 이슈 표현** | 없음 | High Bias | High Variance | High Bias + High Variance |\n",
    "\n",
    "> - **최적 알고리즘 복잡도:** `Bias와 Variance가 최소`가 되는 `복잡도 수준`의 알고리즘 모델링 선택\n",
    ">\n",
    "> - **평균-분산 상충관계(Bias-variance Trade-off):** `복잡도가 증가`할수록 `Bias는 감소`하나 `Variance가 증가`하는 반비례 관계\n",
    ">\n",
    "> <center><img src='Image/Expert/Bias-Variance-Tradeoff.png' width='400'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터에서 편향-분산 상충관계\n",
    "\n",
    "> **\"`비용함수 = 편향 + 분산`를 줄이는 방향으로 `알고리즘이 진화하고 성능이 향상되는 편(이론에서 확인예정)`이지만, <br>\n",
    "알고리즘 성능은 `데이터에 의존`되어 있기 때문에 고성능 알고리즘이 `무조건 나의 데이터에서 성능이 좋을거라 단정할 순 없고`, <br>\n",
    "나의 데이터에 `여러 알고리즘을 적용하여 성능 분포나 변화를 확인`하여, <br> `과소/과대적합 되지 않는` 또는 편향과 분산이 모두 최소가 되는 `최적 알고리즘을 선택`하는것이 최적 모델링 방향\"**\n",
    "\n",
    "---\n",
    "\n",
    "**1) Train 적절하게 학습 후 Test의 예측성능 종류:** \n",
    "\n",
    "**\"Train 데이터는 편향과 분산이 없게 모델링을 하더라도, `Test는 Train과 차이가 있는 데이터`이기 때문에 다양한 결과 가능\"**\n",
    "\n",
    "> **(1) Train(2,1) & Train(1,2) & Train(2,2):** 알고리즘이 Train에 `과소/과대적합`되어 추가적인 모델링 성능 향상부터 필요하며 당연히 `Test 예측에 활용 불가`\n",
    ">\n",
    "> <center><img src='Image/Expert/Bias_Variance2.jpeg' width='400'>(붉은색: Target, 파란색: Predicted)</center>\n",
    ">\n",
    "> **(2) Train(1,1):** 알고리즘이 Train에 `최적/과대적합`되어 `Train 예측에는 활용 가능`\n",
    ">\n",
    "> | **Test 예측 상황** | **결과 설명 및 의미** |\n",
    "|:---:|:---|\n",
    "| **(2,1)** | - 알고리즘이 Train학습 후 Test `예측성능은 부정확한 편`이며 측정마다 `일정하게 부정확`<br> - 알고리즘이 `Train`에 `최적적합`이지만 다른 데이터인 `Test`에는 `과소적합(더욱 복잡한 패턴 존재)`이라서 예측시 `High Bias` 발생 |\n",
    "| **(1,2)** | - 알고리즘이 Train학습 후 Test `예측성능은 정확한 편`인데 측정마다 `기복이 심함`<br> - 알고리즘이 `Train`에 `과대적합`이라 다른 데이터인 `Test` 예측시 `High Variance` 발생 |\n",
    "| **(2,2)** | - 알고리즘이 Train학습 후 Test `예측성능은 부정확한 편`이며 측정마다 달라져서 `더욱 부정확할 수 있게 기복이 심함`<br> - 알고리즘이 `Train`에 `과대적합`이라 다른 데이터인 `Test` 예측시 `High Variance` 발생 가능하며, 또한 상대적으로 `Test`에는 `과소적합(더욱 복잡한 패턴 존재)`이라서 예측시 `High Bias` 발생 |\n",
    "   \n",
    "---\n",
    "\n",
    "**2) 알고리즘 복잡도 별 Train/Test 성능:** `Bias & Variance 모두 감소`시키는건 `어려움`\n",
    "\n",
    "| **알고리즘(복잡도)** | **Train 학습 특징** | **Train 성능** | Test 성능 |\n",
    "|:---|:---|:---|:---|\n",
    "| **과소적합(낮음)** | 데이터 <span style=\"color:red\">일부 패턴만</span> 학습 | <span   style=\"color:red\">낮음: High Bias</span> + Low Variance | <span   style=\"color:red\">낮음: High Bias</span> + Low Variance |\n",
    "| **최적적합(적정)** | 데이터 <span style=\"color:red\">모든 패턴</span> 학습 | 적정: Low Bias + Low Variance | 적정: Log/<span style=\"color:red\">Middle Bias</span> + Low Variance |\n",
    "| **과대적합(높음)** | 데이터 <span style=\"color:red\">모든 패턴 및 잡음/에러까지</span> 학습 | 높음: Low Bias + Low Variance | <span   style=\"color:red\">낮음:</span> Low/<span   style=\"color:red\">Middle Bias + High Variance</span> |\n",
    "\n",
    "- **평균-분산 상충관계(Bias-variance Trade-off):** `복잡도가 증가`할수록 `Bias는 감소`하나 `Variance가 증가`하는 반비례 관계\n",
    "\n",
    "> - **Train:** `복잡도가 증가`할수록 `Bias 감소 + Variance 감소`\n",
    "> - **Test:** `복잡도가 증가`할수록 `Bias 감소 가능 + Variance 증가`\n",
    ">\n",
    "> - **Underfitting:** Train 패턴 `적게 학습`하여, `주로 Bias 때문에 Train/Test 성능 낮음`\n",
    "> - **Overfitting:** Train 패턴 `과하게 학습`하여, `주로 Variance 때문에 Test 성능 낮음`\n",
    ">\n",
    "> <center><img src='Image/Expert/Bias_Variance4.png' width='400'></center>\n",
    ">\n",
    "> **\"알고리즘이 복잡해지면 `Bias와 Variance는 모두 감소하는 경항`이지만, `어느 시점(Train 패턴과 다른 패턴이 Test에 나타나는 시점)`부터는 Variance가 증가하여 `Test의 비용함수/에러가 증가`\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적 데이터 분석 방향\n",
    "\n",
    "**0) Train/Test 성능:** `Train <<< Test`\n",
    "\n",
    "<center><img src='Image/Expert/DataSplit_Concept1.png' width='700'></center>\n",
    "<center><img src='Image/Expert/DataSplit_Concept2.png' width='700'></center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/Expert/Bias_Variance4.png' width='400'></center>\n",
    "\n",
    "---\n",
    "\n",
    "- **예시:** `비용함수(Cost Function)` = `편향(Bias)` + `분산(Variance)` + `에러(Error)`\n",
    "\n",
    "<center><img src='Image/Expert/Bias_Variance_Example1.jpg' width='700'></center>\n",
    "<center><img src='Image/Expert/Bias_Variance_Example2.jpg' width='700'></center>\n",
    "<center><img src='Image/Expert/Bias_Variance_Example3.jpg' width='700'>(https://datacadamia.com/data_mining/bias_trade-off)</center>\n",
    "\n",
    "---\n",
    "\n",
    "**1) 최적 방향:** `Bias & Variance 모두 감소`시키는건 `어려움`\n",
    "\n",
    "> **(1)** `성능 시각화`를 통해 `Train 데이터 패턴`이 `과하게 학습`되어 다른 데이터나 환경의 적은 변동에도 `Test 성능이 급하게/안정적으로 변하는지 측정` (Train <<< Test)\n",
    ">\n",
    "> **(2)** `Bias & Variance 모두 낮게 교차`하는 알고리즘 복잡도가 적용된 모델링 결과 선택\n",
    ">\n",
    "> **(3)** 추가적으로 `Train/Test의 차이를 줄이는 것`도 방법 => <span style=\"color:red\">$K$-fold Cross Validation 배경</span>\n",
    "\n",
    "- **$K$-fold**\n",
    "<center><img src='Image/Expert/DataSplit_ver1.png' width='500'></center>\n",
    "\n",
    "- **Random-subsamples**\n",
    "<center><img src='Image/Expert/DataSplit_ver2.png' width='500'></center>\n",
    "\n",
    "- **Leave-one-out**\n",
    "<center><img src='Image/Expert/DataSplit_ver3.png' width='500'></center>\n",
    "\n",
    "- **Leave-$p$-out**\n",
    "<center><img src='Image/Expert/DataSplit_ver4.png' width='500'></center>\n",
    "\n",
    "---\n",
    "\n",
    "**2) 실제 데이터분석 접근 방법:** `편향과 분산 모두 최소화`하기 위해 `반복적`으로 업데이트\n",
    "\n",
    "> **\"`Train` 데이터의 `Bias가 적절(낮게)`한지 확인 후, `Test 데이터`에 적용하여 `Variance가 적절(낮게)하도록 반복적 업데이트`\"**\n",
    ">\n",
    "> - Train의 Bias가 높다면,  `알고리즘 복잡하게` 또는 `빅데이터(Row & Column)` 또는 `최적화`를 통해 해결\n",
    ">\n",
    "> - Test의 Variance가 높다면, `알고리즘 덜 복잡하게` 또는 `빅데이터(Row) & 스몰데이터(Column)` 또는 `최적화`를 통해 해결\n",
    ">\n",
    "> <center><img src='Image/Expert/Bias_Variance_Reduce.png' width='600'></center>\n",
    ">\n",
    "> - **딥러닝(인공지능 알고리즘):** 딥러닝은 `엄청나게 복잡한 모델`이며 `Bias-variance Trade-off를 피할 수 없음`\n",
    ">\n",
    "> - `스몰데이터`의 딥러닝은 `과대적합`되어 `High Variance`가 우려되기에, `딥러닝`으로 성능을 내기 위해선 `빅데이터`가 반드시 필요!\n",
    ">\n",
    "> - `빅데이터`를 통해 `Train과 Test의 패턴 차이 감소`되어 `Bias & Variance를 모두 감소시키기 유리`"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "702.4px",
    "left": "21px",
    "top": "123.525px",
    "width": "393px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
