{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **다양한 딥러닝 알고리즘의 등장**\n",
    "\n",
    "[![Open in Colab](http://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thekimk/All-About-Deep-Learning/blob/main/Lecture4-3_DeepLearning_BaseAlgorithms_KK.ipynb)\n",
    "\n",
    "> **\"인공지능 알고리즘은 지난 60여 년 동안 `두 번의 침체기와 두 번의 전성기`를 겪었고\n",
    "현재 인공지능은 `세 번째 전성기 대두`\"**\n",
    ">\n",
    "> - **1차 전성기(1950년대 후반~1960년대 초):** 추론과 탐색 기법 중심이었으나 `간단한 문제를 해결`하는 것 외에 `뚜렷한 가능성을 제시하지 못하고` 곧바로 1차 침체기를 경험함\n",
    ">\n",
    "> - **2차 전성기(1980년대 후반~1990년대 초):** `특정 분야`에서 `정해진 규칙에 따라 전문가시스템`을 구축하는 방식이었으나 `확장성 측면에서 한계`를 보이며 2차 침체기를 맞이함\n",
    ">\n",
    "> - `2012년 ImageNet Challenge 대회`에서 딥러닝이 압도적 성능으로 우승한 이후 `DNN/CNN/RNN 등 알고리즘이 비약적으로 발전`\n",
    ">\n",
    "> - 신경망의 `고전적 문제들은 대부분 해결`되고 `빅데이터`의 폭발적인 증가와 `하드웨어 기술의 발전`으로 산업에 본격적으로 활용\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**0) MLP(Multi-Layered Perceptron):** 데이터의 `패턴 또는 지식`을 추론하는 `다층퍼셉트론 방법`\n",
    "\n",
    "- 은닉층의 수가 증가하면 더욱 어려운 문제를 풀수 있는데, 통상 `은닉층을 최소 2개이상 가진 알고리즘`을 `딥러닝(Deep Learning)` 알고리즘 이라고 함\n",
    "\n",
    "<center><img src='Image/Expert/DL_MLP_Custom.PNG' width='500'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Convolutional Neural Network(CNN) 발전\n",
    "\n",
    "<center><img src='Image/Expert/CNN_Example.webp' width='900'></center>\n",
    "\n",
    "- `기존`의 방식은 `데이터에서 지식을 추출`해 학습이 이루어졌지만, CNN은 `데이터의 특징을 추출하여 특징들의 패턴을 파악`하는 구조\n",
    "\n",
    "- `이미지처리`를 위해 특수 고안된 구조로 `데이터의 패턴을 추출하고(Convolution) 차원을 줄여 일반적인 패턴으로 정교화(Pooling)`하는 층으로 구성\n",
    "\n",
    "> - `Lenet5 (1998)`\n",
    "> - `Alexnet (2012)`\n",
    "> - `ZFNet (2013)`\n",
    "> - `VGGNet (2014)`\n",
    "> - `GoogLeNet (2014)`\n",
    "> - `ResNet (2015)`\n",
    "\n",
    "---\n",
    "\n",
    "**1) Lenet5 (1998)**\n",
    "\n",
    "> <center><img src='Image/Expert/CNN_Lenet5.PNG' width='800'>(A Shallow Convolutional Neural Network for Accurate Handwritten Digits Classification, 2017)</center>\n",
    ">\n",
    "> - Image Classification에 거의 보편적으로 사용되는 `Convolutional Neural Network(CNN)을 최초로 제안한 논문`인 Yann LeCun의 LeNet-5\n",
    "> - MLP가 가지는 한계점인 `입력 pixel수가 많아지면 parameter가 기하급수적으로 증가`하는 문제, `국소 이미지의 왜곡 문제 등`을 지적하며, 이러한 문제를 해결할 수 있는 `Convolutional Neural Network 구조를 처음 제안`\n",
    "> - `입력층을 1차원적 관점에서 2차원으로 확장`하였고, `추정 가중치를 공유`하기 때문에 입력 데이터수가 증가해도 `파라미터 수가 변하지 않아 학습속도가 빠르고 일반화 능력 우수`\n",
    "> - `그레이스케일 입력 이미지`로 `디지털화된 수표(수표)의 손으로 쓴 숫자를 인식`하기 위해 여러 `은행에서 적용`\n",
    "\n",
    "---\n",
    "\n",
    "**2) Alexnet (2012)**\n",
    "\n",
    "> <center><img src='Image/Expert/CNN_AlexNet.PNG' width='700'>(ImageNet Classification with Deep Convolutional)</center>\n",
    ">\n",
    "> - Classification 성능을 겨루는 대회인 `ILSVRC 대회`가 2010년부터 매년 열렸는데, SuperVision 이라는 이름의 팀이 `2012년 압도적인 성능으로 우승`하게 되고 이때 사용한 모델이 AlexNet\n",
    "> - AlexNet은 Alex Krizhevsky, Geoffrey Hinton 및 Ilya Sutskever 교수진이 개발한 `딥러닝의 혁명을 일으킨 CNN 모델`\n",
    "> - `활성함수는 ReLU + GPU를 사용한 Convolution 연산`\n",
    "> - Lenet5에 비해 학습시간 단축 및 `Dropout 및 PCA를 이용한 Data Augmentation으로 과적합 방지`\n",
    "\n",
    "---\n",
    "\n",
    "**3) ZFNet (2013)**\n",
    "\n",
    "> <center><img src='Image/Expert/CNN_ZFNet.PNG' width='800'>(Visualizing and Understanding Convolutional Networks)</center>\n",
    ">\n",
    "> - `ILSVRC 2013 대회에서 우승`한 Clarifai 팀의 Zeiler와 Fergus의 이름을 따서 지은 ZFNet\n",
    "> - `AlexNet을 기반`으로 첫 Conv layer의 filter size를 11에서 7로, stride를 4에서 2로 바꾸고, 그 뒤의 Conv layer들의 filter 개수를 키워주는 등(Conv3,4,5: 384, 384, 256 –> 512, 1024, 512) 약간의 튜닝\n",
    "> - 학습이 진행됨에 따라 `Feature Map을 시각화`하는 방법과, 모델이 `어느 영역을 보고 예측을 하는지 관찰`하기 위한 Occlusion 기반의 Attribution 기법 등 `시각화 측면에 집중`\n",
    "\n",
    "---\n",
    "\n",
    "**4) VGGNet (2014)**\n",
    "\n",
    "> <center><img src='Image/Expert/CNN_VGGNet_Comparison.png' width='600'>(http://cs231n.stanford.edu/)</center>\n",
    ">\n",
    "> - `옥스포드 연구진에서 2014년` 발표한 VGG로 `ILSVRC 2014 대회에서 2위`의 성적\n",
    "> - 이전 방식들과는 다르게 `비교적 작은 크기인 3x3 convolution filter를 깊게 쌓는다`는 것이 VGG의 핵심\n",
    "> - 현재 `이미지 패턴 추출 커뮤니티에서 가장 선호되는` 방식 중 하나\n",
    "> - 오류율이 7.3%로 줄어들어 `정상적인 사람의 이미지 분류성능과 매우 근접한 수준`\n",
    "\n",
    "---\n",
    "\n",
    "**5) GoogLeNet (2014)**\n",
    "\n",
    "> <center><img src='Image/Expert/CNN_GoogLeNet.png' width='800'>(Design and Development of Diabetes Management System Using Machine Learning)</center>\n",
    ">\n",
    "> - `ILSVRC 2014 대회에서 1위`를 하였으며 `Inception Architecture라는 예명`\n",
    "> - GoogLeNet을 기점으로 `거대 기업들이 뛰어들었다는 점`이 주목할만 하고 `Google과 LeNet을 합쳐서 작명`\n",
    ">\n",
    "> - **기업연구 예시:**\n",
    ">\n",
    "> <center><img src='Image/Expert/Recommendation_AlgorithmHistory.png' width='800'></center>\n",
    ">\n",
    "> - `Global Average Pooling(GAP)`를 사용하여 총 1024개의 노드를 만든 뒤 class 개수(ImageNet=1000)의 output을 출력하도록 하나의 Fully-Connected layer만 사용하여 AlexNet, ZFNet, VGG 등에 비해 `훨씬 적은 수의 파라미터`\n",
    "> - 22층의 `CNN으로 입센셥 모듈이라는 블록을 반복 사용`하는 모델\n",
    "> - 인셉션 모듈은 `CNN의 최적 희소구조를 찾아내고 이를 사용가능한 패턴으로 근사`\n",
    "\n",
    "---\n",
    "\n",
    "**6) ResNet (2015)**\n",
    "\n",
    "> <center><img src='Image/Expert/CNN_ResNet.PNG' width='1000'>(Deep Residual Learning for Image Recognition)</center>\n",
    ">\n",
    "> - `Microsoft Research`에서 제안한 구조이며 `ILSVRC 2015 대회에서 1위`를 차지하며 `최초로 사람의 분류 성능을 뛰어넘은 모델`로 평가\n",
    "> - Layer의 개수에 따라 `ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152 등 5가지 버전`으로 나타낼 수 있으며, ILSVRC 2015 대회에선 ResNet-152로 1위를 차지\n",
    "> - `152개의 레이어`로 훈련할 수 있고 `인간 수준의 성능을 능가하는 3.57% 오류율`\n",
    "> - 층이 많아지다 보니 연산량도 많아지게 되는데, Inception module에서 보았던 `Bottleneck 구조를 차용하여 Bottleneck Residual Block 을 중첩하여 사용`하는 점이 특징\n",
    "> - 이후 모델은 `ResNeXt, DenseNet, MobileNets 등`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network(RNN) 발전\n",
    "\n",
    "> **\"일상 생활에서의 `기계변역, 음성인식, 텍스트분류, DNA 시퀀싱 분석 등` Sequential Modeling 이슈는 항상 존재하며 `대부분 지도학습`에 속하고, `입력과 출력의 크기는 가변적`\"**\n",
    ">\n",
    "> - 1986년에 개발되어 `반복적이고 순차적인 데이터(Sequential data)학습에 특화`된 인공신경망의 한 종류로써 내부 뉴런들이 순환구조로 연결되어 `과거 정보를 기억하는 특징`이 있고 `입출력의 크기를 가변적 조절 가능`\n",
    "\n",
    "<center><img src='Image/Expert/RNN_Example.webp' width='400'>(https://medium.datadriveninvestor.com/recurrent-neural-network-with-keras-b5b5f6fe5187)</center>\n",
    "\n",
    "- 순환구조를 이용하여 `과거의 학습을 Weight를 통해 현재 학습에 반영`\n",
    "- 기존의 지속적이고 `반복적이며 순차적인 데이터학습의 한계를 해결`한 알고리즘\n",
    "- `현재의 학습과 과거의 학습의 연결`을 가능하게 하고 `시간에 종속`된다는 특징\n",
    "- 훨씬 많은 정보와 공간이 있는 이미지와 달리, `데이터가 적은 경우도 있고 시간을 핸들링 해야해서 RNN 아키텍처의 종류는 그렇게 다양하진 않음` \n",
    "- RNN 발전의 핵심은 `과거의 중요한 정보를 최대한 많이 기억하려는 방향`\n",
    "- CNN으로도 적절한 데이터 처리로 시간 핸들링이 가능할 순 있지만 `쉽지 않으며 굳이 성격이 다른 CNN을 고집할 필요 없음`\n",
    "\n",
    "> - `RNN (1986)`\n",
    "> - `LSTM (1997)`\n",
    "> - `GRU (2014)`\n",
    "> - `Sequence-to-Sequence (Seq2Seq, 2014)`\n",
    "> - `Attention (2015)`\n",
    "> - `Transformer (2017)`\n",
    "\n",
    "---\n",
    "\n",
    "**0) RNN의 다양한 입출력 처리:** `일반적 신경망`은 `다양한 크기의 입출력 처리 어려움`\n",
    "\n",
    "- **장점:** 크게 4가지 유형으로 분류되며 `무엇을 입력/출력하는지에 따라 유연하게 활용` 가능\n",
    "\n",
    "<center><img src='Image/Expert/DL_RNN_Type.PNG' width='700'></center>\n",
    "\n",
    "> - **One-to-One:** Vanilla Neural Networks\n",
    "> - **One-to-Many:** Image Captioning, Target Explanation\n",
    "> - **Many-to-One:** Classification, Time Series Analysis, Sentiment Analysis, Spam Detection\n",
    "> - **Many-to-Many:** Time Series Analysis, Machine Translation, Prediction of Next Word, Video Classification (`return_sequences = True`)\n",
    "\n",
    "- **단점:** `과거를 기억하는 어려움` 및 기울기가 0이 되거나 폭발하여 `메모리 부족`\n",
    "\n",
    "---\n",
    "\n",
    "**1) LSTM (1997)**\n",
    "\n",
    "> <center><img src='Image/Expert/LSTM_Architecture.PNG' width='700'>(https://blog.mlreview.com/understanding-lstm-and-its-diagrams-37e2f46f1714)</center>\n",
    ">\n",
    "> - `기존 RNN`이 소수의 매개변수가 너무 많은 과거 정보를 처리 및 기억하여 `쉽게 과부화 되는 이슈를 해결`한 가장 인기있는 아키텍처\n",
    "> - 과거의 정보 중`잊어도 되는 정보 + 강조되어야 하는 정보 + 출력할 것`으로 선택적 처리 반영\n",
    "> - 서로 다른 목적의 `3가지의 논리층`이 `장단기 정보의 기억 성능`을 크게 향상\n",
    "\n",
    "---\n",
    "\n",
    "**2) GRU (2014)**\n",
    "\n",
    "> <center><img src='Image/Expert/DL_LSTM_GRU.png' width='700'>(https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)</center>\n",
    ">\n",
    "> - `LSTM보다 간략화한 구조`로 뉴욕대 한국인 조경현 교수님이 개발 (Cho et al. 2014)\n",
    "> - LSTM의 개념은 유지한 채 `매개변수를 줄여 계산 시간을 크게 줄임`\n",
    "> - LSTM과 하이퍼파라미터 설정에 따라 성능이 달라지겠지만, `데이터셋이 적거나 모델의 반복 시도가 많은 경우` 특히 적합할 수 있음\n",
    "\n",
    "---\n",
    "\n",
    "**3) Sequence-to-Sequence (Seq2Seq, 2014)**\n",
    "\n",
    "> <center><img src='Image/Expert/Seq2Seq_Arch1.PNG' width='800'>(https://wikidocs.net/24996)</center>\n",
    ">\n",
    "> <center><img src='Image/Expert/Seq2Seq_Arch2.PNG' width='800'>(https://jeddy92.github.io/)</center>\n",
    ">\n",
    "> - Encoder와 Decoder라는 개념을 사용한 `2개의 RNN을 연결(Many-to-One + One-to-Many)`하여 `하나의 시계열 데이터를 다른 시계열로 변환`\n",
    "> - 구조적으로 `고정 크기의 벡터에 정보를 압축`하다보니 `정보손실 발생`\n",
    "> - 여전히 `병렬처리가 어렵고 많은 계산 복잡도`\n",
    "> - `입력데이터가 길어지면 성능이 크게 하락`되는 현상 존재\n",
    "> - 이후 개발된 `Attention & Transformer`가 등장하기 전까지 `딥러닝 기반 번역의 돌파구 역할`\n",
    "---\n",
    "\n",
    "**4) Attention (2015)**\n",
    "\n",
    "> <center><img src='Image/Expert/Attention_Architecture.PPM' width='600'>(Neural Abstractive Text Summarization with Sequence-to-Sequence Models)</center>\n",
    ">\n",
    "> - Seq2Seq의 Encoder에서 `일정 크기로 정보를 압축하다 정보손실이 발생하는 문제 보완`\n",
    "> - Encoder의 압축정보 이외에 `Decoder의 전체 입력 데이터를 추가 검토하여 중요도 반영`\n",
    "> - 해당 시점에 `예측해야 할 데이터와 관련있는 입력데이터를 조금 더 집중`해서 반영\n",
    "> - 즉, 반영되지 않은 은닉층의 정보 중 `출력층과 연관성이 높은데이터에 가중치` \n",
    "> - Decoder가 Encoder에 입력되는 모든 단어의 정보를 활용할 수 있기 때문에 `장기 의존성 문제를 해결`\n",
    "> - 여전히 `병렬처리가 어려운 근본적인 단점과 많은 계산 복잡도`\n",
    "\n",
    "---\n",
    "\n",
    "**5) Transformer (2017)**\n",
    "\n",
    "> <center><img src='Image/Expert/Transformer_Architecture.PNG' width='900'>([CS224n] Lecture 14: Transformers and Self-Attention for Generative Models)</center>\n",
    ">\n",
    "> - `RNN을 기반으로 하지 않는` 또다른 Encoder-Decoder 구조\n",
    "> - 인간의 뇌에서 정보를 `잠재공간(Latent Space)`에 저장 후 `다양한 분야에 재활용` 응용\n",
    "> - Attention 알고리즘의 단점인 `계산 복잡도를 줄임`\n",
    "> - 입력 데이터의 관계정보를 `병렬처리를 통한 Self-attention`을 사용하여 미리 계산 및 저장하여 `미래 데이터를 효율적으로 예측`\n",
    "> - Self-Attention을 동시에 여러개로 수행하고 `Step마다 다른 Attention 결과`가 제시되어 `앙상블과 유사한 효과`\n",
    "> - 데이터를 학습할 때 `CNN과 RNN 보다 유의하게 더욱 빠르며 입출력 데이터의 거리에 관계없이 동작가능`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN vs RNN 알고리즘**\n",
    "\n",
    "> **\"`문제 유형`에 따라 적절한 아키텍쳐 선택!\"**\n",
    "\n",
    "<center><img src='Image/Expert/DL_Comparing_CNNRNN.png' width='800'></center>\n",
    "\n",
    "| 데이터 | 분야 | 알고리즘 |\n",
    "|:-:|:-:|:-:|\n",
    "| **스냅샷<br>(Snapshot)** | `이미지, 영상, 바둑` (시간 무관) | CNN계열 |\n",
    "| **시퀀스<br>(Sequence)** | `기상, 주가, 언어, 음성` (시간 연관) | RNN계열 |\n",
    "\n",
    "---\n",
    "\n",
    "**1) CNN:** `이미지`처럼 `여러 값뭉치로 패턴이 존재하는 데이터를 처리하는데 특화`된 모델\n",
    "\n",
    "- 이미지나 영상에서의 `인식이나 분류 문제 등`에서 뛰어난 결과\n",
    "- 입력 데이터보다 `더 큰 데이터의 패턴으로 손쉽게 확장`될 수 있는 특징\n",
    "- 각 `은닉층 노드`의 연산이 `한번만 실행`\n",
    "\n",
    "> - `Lenet5 (1998)`\n",
    "> - `Alexnet (2012)`\n",
    "> - `ZFNet (2013)`\n",
    "> - `VGGNet (2014)`\n",
    "> - `GoogLeNet (2014)`\n",
    "> - `ResNet (2015)`\n",
    "\n",
    "**2) RNN:** `순서가 있는 데이터(시계열, 자연어 등)를 처리하는데 특화`된 모델\n",
    "\n",
    "- `예측`이 가장 큰 분석 목적이자 활용분야\n",
    "- `비현실적으로 긴 시계열`도 쉽게 확장 가능\n",
    "- `가변 길이의 시계열 데이터`도 처리 가능\n",
    "- 각 `은닉층 노드를 공통으로 사용`하여 계속 갱신\n",
    "\n",
    "> - `RNN (1986)`\n",
    "> - `LSTM (1997)`\n",
    "> - `GRU (2014)`\n",
    "> - `Sequence-to-Sequence (Seq2Seq, 2014)`\n",
    "> - `Attention (2015)`\n",
    "> - `Transformer (2017)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network(CNN)\n",
    "\n",
    "> **\"이미지는 `데이터의 의미(Feature/Variable)를 학습하면 비효율적`이고 데이터의 `특징/패턴을 별도 추출`하여 학습하는 신경망 필요 (LeCun et al. 1989)\"**\n",
    ">\n",
    "> - 뇌가 `시각정보를 처리`하기 위해 시각피질을 구성하고 있는 `망막(입력층) -> 단순세포(은닉층) -> 복합세포(출력층)의 기능을 모형`으로 만든 것\n",
    ">\n",
    "<!-- > <center><img src='Image/Expert/CNN_Learning_Ideation.PNG' width='1000'></center> -->\n",
    "> <center><img src='Image/Expert/CNN_Learning_Ideation_False.PNG' width='1000'></center>\n",
    "<!-- > <center><img src='Image/Expert/CNN_Learning_Ideation_True.PNG' width='1000'></center> -->\n",
    ">\n",
    "> - 일반적으로 이미지는 `인접한 픽셀간의 상관성`이 있는데 `벡터화 과정에서 정보 손실` 발생\n",
    ">\n",
    "> <center><img src='Image/Expert/CNN_Vectorization.PNG' width='1000'>(https://sungwookkang.com/1408)</center>\n",
    ">\n",
    "> - 사진 속의 이미지가 `새 라는 것을 인식`해야 하는데 `새의 특징은 강조되어야 하고 주변은 덜 강조되어 학습되어야`\n",
    "> - **CNN 구조:** `1) Convolution Layer + 2) Pooling Layer + 3) Fully Connected Layer & Activation`\n",
    ">\n",
    "> <center><img src='Image/Expert/CNN_Process_Example.webp' width='1000'>(https://towardsdatascience.com/deep-learning-2-f81ebe632d5c)</center>\n",
    "\n",
    "---\n",
    "\n",
    "**1) Convolution Layer:** \n",
    "\n",
    "- 데이터 각 성분의 `인접 주변 정보들을 포함`하여 데이터의 `주요특징을 추출`하여 `한장으로 요약`하는 Layer\n",
    "- 데이터를 `압축/요약하는 과정에서 사용되는 필터를 공유`하여 DNN 대비 `파라미터의 갯수가 현저히 적어서 과적합 문제 덜 발생`\n",
    "- 요약된 정보를 통상 `Convolution Layer`라고, 엄밀히 말하면 `Cross-Correlation(교차상관)`를 사용하여 연산량을 줄이는 방식 사용\n",
    "\n",
    "<center><img src='Image/Expert/CNN_Convolution_Process.PNG' width='700'>(https://chacha95.github.io/2018-12-02-Deeplearning3/)</center>\n",
    "\n",
    "- `입력데이터` $\\rightarrow$ `채널(Channel) 확인` $\\rightarrow$ `필터(Filter)/Stride/패딩(Padding) 결정` $\\rightarrow$ `각 채널 별 합성곱(Convolution)으로 특성추출`\n",
    "\n",
    "> **(1) 채널(Channel):** `입력데이터의 깊이`를 의미\n",
    ">\n",
    "> - `정형데이터=1채널, 흑백이미지=1채널, 컬러이미지=3채널, 시간데이터=시간인텍스 수만큼의 채널`\n",
    "> - 채널이 여러개인 경우 `각 채널별 특성을 추출한 후 결합`시키는 과정 포함\n",
    ">\n",
    "> **(2) 필터(Filter)/Stride/Padding:** `데이터/이미지의 특징을 추출`하기 위한 행렬\n",
    ">\n",
    "> - 필터의 크기는 정해지지 않았으며, 일반적으로 `3*3, 4*4, 5*5 등`의 정사각형 사용\n",
    "> - 만약 `필터의 크기가 입력데이터의 크기와 같다면 DNN과 동일`\n",
    "> - `입력데이터에서 필터의 크기만큼의 데이터(파란색 네모칸)를 추출`하여 `필터를(보라색) 곱해서 합`하여 특성 값 추출\n",
    "> - 필터를 적용한다는 것은, `회귀분석을 1회 실시하는 것 또는 업데이트가 필요한 가중치 파라미터 추정 `\n",
    "> - 분석가가 필터의 값들을 `임의의 랜덤값으로 초기화` 후 `데이터 학습을 통해 최적의 값으로 업데이트`\n",
    "> - 필터 사용을 통해 `가중치를 공유`하게 되고 `필요한 가중치의 수가 대폭 줄어 연산량 감소`\n",
    ">\n",
    "> <center><img src='Image/Expert/CNN_Filter.PNG' width='600'>(https://anhreynolds.com/blogs/cnn.html)</center>\n",
    ">\n",
    "> - **Stride:** `필터가 특성값을 추출`하기 위해 움직이는 간격\n",
    ">\n",
    "> <center><img src='Image/Expert/CNN_Filter_Stride.jpg' width='700'>(https://wikidocs.net/152775)</center>\n",
    ">\n",
    "> - **패딩(Padding):** 데이터 유실을 줄이기 위해 `데이터 외곽에 특정 값(주로 0)으로 채우는 과정`\n",
    "> - 최종 `Feature Map의 크기는 입력데이터의 크기보다 작아지기` 떄문에 입력과 출력 크기를 같거나 비슷하게 맞추는 편\n",
    "> - 패딩이 없다면, `가장자리 부분은 내부 데이터보다 패턴 탐색의 기회가 적어지는` 효과\n",
    "> - 패딩은 사이즈 조절 이외에도 입력데이터에 `특정 값의 노이즈를 섞기 때문에 과적합을 방지`하는 효과\n",
    ">\n",
    "> <center><img src='Image/Expert/CNN_ZeroPadding.gif' width='800'>(https://medium.com/@draj0718/zero-padding-in-convolutional-neural-networks-bf1410438e99)</center>\n",
    ">\n",
    "> - **예시:** `Channel 3개 + Filter 2개 + Stride 2 + Zero Padding`\n",
    "> - 데이터의 `특징이 있다면 큰값`이 출력되고 `특징이 없다면 작은값`이 출력\n",
    "> - `Filter의 갯수`만큼 모델링되어 출력값 생성\n",
    "> - `각 채널 데이터마다 다양한 필터를 적용`해야 다양한 특성 추출\n",
    ">\n",
    "> <center><img src='Image/Expert/CNN_Convolution.gif' width='800'>(https://cs231n.github.io/convolutional-networks/)</center>\n",
    "\n",
    "---\n",
    "\n",
    "**2) Pooling Layer:**\n",
    "\n",
    "- `합성곱 출력값을 입력받아 특정 부분을 선택/강조`하여 사이즈를 줄이는 과정으로 `Sub Sampling`\n",
    "- 하나를 선택하는 방식에 따라 `Min/Average/Max Pooling 등`이 있으며 `Max Pooling`이 주로 사용\n",
    "- 데이터 `노이즈를 상쇄`시키고 `미세한 부분에서 일관적인 특징을 추출`하는 효과\n",
    "- 항상 사용하지는 않고 `데이터의 크기를 줄이고 싶을 때 선택적 사용`하며 `과적합 방지 효과`\n",
    "- `Stride & Padding`은 회귀분석을 하는 일종의 Feature Engineering 기술로 `컨볼루션 뿐만 아니라 풀링에서 사용 가능`\n",
    "\n",
    "<center><img src='Image/Expert/CNN_Pooling.gif' width='600'>(https://towardsdatascience.com/convolutional-neural-networks-explained-how-to-successfully-classify-images-in-python-df829d4ba761)</center>\n",
    "\n",
    "> - `학습 파라미터가 없고 출력값의 채널수의 변경도 없음`\n",
    "> - 오로지 `입력값의 크기만 감소`되어 출력\n",
    "\n",
    "---\n",
    "\n",
    "**3) Fully Connected Layer & Activation:**\n",
    "\n",
    "- 지금까지 처리된 `행렬형태의 출력값들`을 가진 `모든 노드들을 연결시켜 최종 목적에 부합하는 형태의 1차원 열벡터(One-hot Vector)로 표시`\n",
    "- 목적의 형태에 따라서 사용하지 않을 수도 있어서 `필수는 아니지만 기본적으로 사용하는 편`\n",
    "\n",
    "<center><img src='Image/Expert/CNN_Process_BlackImage.PNG' width='800'>(https://all-young.tistory.com/43)</center>\n",
    "\n",
    "> - 다중분류에 Softmax 함수를 쓰며, `목적에 맞는 적절한 활성화 함수 반영`\n",
    "\n",
    "---\n",
    "\n",
    "**4) MLP $\\rightarrow$ CNN:**\n",
    "\n",
    "<center><img src='Image/Expert/CNN_Learning_Ideation_False.PNG' width='1000'></center>\n",
    "\n",
    "- MLP에서 `Batch로 Row를 반영`되어 각 Row의 라벨을 예측하듯, CNN도 `Batch로 Image가 반영`되어 각 Image의 라벨을 예측!\n",
    "\n",
    "<center><img src='Image/Expert/CNN_Learning_Ideation_True.PNG' width='1000'></center>\n",
    "\n",
    "- CNN은 MLP 학습 전에 `Image의 패턴을 요약한 숫자로 변환하는 과정이 추가`된 것\n",
    "\n",
    "<center><img src='Image/Expert/CNN_ConvPoolFC.PNG' width='800'></center>\n",
    "\n",
    "---\n",
    "\n",
    "**5) 각 층별 학습된 패턴 예시:**\n",
    "\n",
    "<center><img src='Image/Expert/CNN_Layer2.webp' width='700'></center>\n",
    "<center><img src='Image/Expert/CNN_Layer3.webp' width='700'></center>\n",
    "<center><img src='Image/Expert/CNN_Layer4_Layer5.webp' width='700'>(https://towardsdatascience.com/deep-learning-2-f81ebe632d5c)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network(RNN)\n",
    "\n",
    "> **\"단방향 신경망 외에 `이전 출력값이 다시 입력으로 연결되는 순환신경망`(Rumelhart et al.1986)\"**\n",
    ">\n",
    "> - 길이가 T인 시계열은 각 시간마다 은닉상태가 계산되지만, `모듈화를 생각해 하나의 층으로 구현`\n",
    ">\n",
    "> <center><img src='Image/Expert/DL_RNN_UnfoldFold.PNG' width='600'></center>\n",
    ">\n",
    "> <center><img src='Image/Expert/DL_Understand_Flow.jpg' width='600'>(http://colah.github.io/posts/2015-08-Understanding-LSTMs/)</center>\n",
    ">\n",
    "> - **예시: `Many-to-Many`**\n",
    ">\n",
    "> <center><img src='Image/Expert/DL_RNN_Example.PNG' width='600'></center>\n",
    "> <center><img src='Image/Expert/DL_RNN_Flow_Example.png' width='500'>(http://cs231n.stanford.edu/2017/syllabus.html)</center>\n",
    ">\n",
    "> - `다음 시점의 예측값 확률`을 출력하며 `매 시점마다 정답에 가깝도록 가중치 평가`(초록색 강화 및 빨간색 약화)\n",
    "\n",
    "---\n",
    "\n",
    "**1) 순전파:**\n",
    "\n",
    "<!-- <center><img src='Image/Expert/DL_RNN_LSTM_Compare1.PNG' width='600'>(http://colah.github.io/posts/2015-08-Understanding-LSTMs/)</center> -->\n",
    "\n",
    "- `입력과 출력 길이의 제한이 없고` 기본적으로 `Fully Connected Layer 구조`\n",
    "- $t$는 시간을 의미하며 `가중치들은 모든 시점들에 공유`됨\n",
    "- `입력데이터`($X_t$)가 RNN 모형에 들어가면, `이전 은닉층값`($H_{t-1}$)과 `특정 가중치`($W, U$)로 결합하여 `새로운 은닉층값`($H_t$) 생성\n",
    "\n",
    "> **(1) 은닉층:** $H_t = f(H_{t-1}, X_t) = \\sigma_H (U H_{t-1} + W X_t) = tanh (U H_{t-1} + W X_t)$ \n",
    ">\n",
    "> - **$X_t$:** `입력값`으로, $m(입력차원수) \\times n(배치크기)$\n",
    "> - **$W$:**: `입력값과 은닉층 사이의 가중치`로, $k(은닉차원수) \\times m(입력차원수)$\n",
    "> - **$H_{t-1}$:** `이전시점의 은닉층값`으로, $k(은닉차원수) \\times n(배치크기)$\n",
    "> - **$U$:**: `이전 은닉층과 현재 은닉층 사이의 가중치`로, $k(은닉차원수) \\times k(은닉차원수)$\n",
    "> - **$H_{t}$:** `현재시점의 은닉층값`으로, $k(은닉차원수) \\times n(배치크기)$\n",
    ">\n",
    "> **(2) 출력층:** $Y_t = f(H_t) = \\sigma_Y (VH_t) = softmax(VH_t)$\n",
    ">\n",
    "> - **$H_{t}$:** `현재시점의 은닉층값`으로, $k(은닉차원수) \\times n(배치크기)$\n",
    "> - **$V$:**: `현재 은닉층과 출력값 사이의 가중치`로, $o(출력차원수) \\times k(은닉차원수)$\n",
    "> - **$Y_t$:** `출력값`으로, $o(출력차원수) \\times n(배치크기)$\n",
    "\n",
    "- 비선형 활성화 함수들 중 `tanh 및 softmax 사용`\n",
    "\n",
    "<center><img src='Image/Expert/DL_RNN_Activation_Without.gif' width='800'></center>\n",
    "<center><img src='Image/Expert/DL_RNN_Activation_With.gif' width='800'></center>\n",
    "<!-- (https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21) -->\n",
    "\n",
    "---\n",
    "\n",
    "**2) 역전파:** `각 시점마다` 비용함수를 평가하여 최소가 될때까지 `반복적으로 가중치 업데이트`($V, U, W$)\n",
    "\n",
    "<center><img src='Image/Expert/DL_RNN_Cycle.JPG' width='900'>(https://www.techleer.com/articles/185-backpropagation-through-time-recurrent-neural-network-training-technique/)</center>\n",
    "\n",
    "---\n",
    "\n",
    "**3) 한계(Bengio et al.1994):** \n",
    "\n",
    "- **Long-term Dependency(현상):** 은닉층의 과거 정보가 `마지막까지 전달되지 못하는` 현상(성능 하락)\n",
    "\n",
    "> - $H_t = \\sigma_H (U H_{t-1} + W X_t) = \\sigma_H (U \\sigma_H (U H_{t-2} + W X_{t-1}) + W X_t)$  \n",
    ">\n",
    "> $\\rightarrow$ `마지막 단어를 예측`한다고 할 때 `초반 단어가 뒷단까지 충분히 전달되기 어려워` 예측 어려움\n",
    ">\n",
    "> <center><img src='Image/Expert/DL_RNN_LongDepend.PNG' width='600'></center>\n",
    "\n",
    "- **Vanishing Gradients(원인):** 입출력의 거리가 멀면 `역전파시 기울기가 작아지던가 커져서 학습능력 저하(RNN 구조문제)`\n",
    "\n",
    "> - 가중치의 최대값 중 하나가 `1보다 크면/작으면 폭발적으로 증가할/감소할 것`\n",
    ">\n",
    "> <center><img src='Image/Expert/DL_RNN_VanishingGradient.png' width='700'>(https://mblogthumb-phinf.pstatic.net/)</center>\n",
    ">\n",
    "> $\\rightarrow$ 가장 일반적인 해결책은 `sigmoid나 tanh 대신 relu 사용`하는 것이지만, `RNN 계열은 같은 레이어를 반복하기 때문에 미사용`\n",
    ">\n",
    "> $\\rightarrow$ 기울기가 커지는 경우는 `기울기의 한계점을 두어 상한선 부여`(Gradient Clipping)\n",
    ">\n",
    "> $\\rightarrow$ 특정 범위의 비용함수만 전파시키는 `Truncated 역전파`를 사용하거나 `LSTM 사용`\n",
    ">\n",
    "> **(1) Truncated Backpropagation:** `Sequence가 매우 길면` 모델링 과정의 순전파와 역전파에 `시간적 비용이 매우 크기 때문에 일정한 크기(보통 5-step) 내의 비용함수 사용`\n",
    ">\n",
    "> <center><img src='Image/Expert/RNN_TruncatedBP.jfif' width='800'>(https://noru-jumping-in-the-mountains.tistory.com/m/13)</center>\n",
    ">\n",
    "> **(2)** 장기간의 과거정보를 기억하기 위한 Cell이 반영된 `LSTM과 GRU`\n",
    ">\n",
    "> <center><img src='Image/Expert/DL_LSTM_GRU.png' width='700'>(https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory\n",
    "\n",
    "> **\"`RNN의 장기기억문제 해결책`으로 고안되었으며 당시는 관심이 낮았지만, `2000년대부터 폭발적인 관심으로 주요 RNN 모델`로 자리잡음 (Hochreiter et al. 1997)\"**  \n",
    ">\n",
    "> - `오래전데이터(Long Term)와 최근데이터(Short Term)를 함께 기억(Memory)`하여 출력\n",
    "> - 일정한 오류를 유지함으로써 여러 네트워크가 `장시간(1000개 이상)에 걸쳐 학습 가능`하도록 함\n",
    "> - 여러개의 `Cell 개념을 도입`하여 열리고 닫히는 게이트를 통해 `어떤 데이터를 읽기/저장/삭제 등 결정`\n",
    ">\n",
    "> <center><img src='Image/Expert/DL_RNN_LSTM_Compare1.PNG' width='600'></center>\n",
    "> <center><img src='Image/Expert/DL_RNN_LSTM_Compare2.PNG' width='600'>(http://colah.github.io/posts/2015-08-Understanding-LSTMs/)</center>\n",
    ">\n",
    "> - 기존 RNN에 Cell State($C$)를 추가하여 `얼마나 과거의 데이터를 기억할지` 결정\n",
    "> - RNN의 은닉층을 `LSTM Block`으로 대체되며 기존 $H$에 $C$가 추가된 네트워크 구조\n",
    "\n",
    "---\n",
    "\n",
    "**1) LSTM Block:** \n",
    "\n",
    "- `RNN 구조를 기반`으로 하되, 은닉층에서 무작정 합성곱을 하지 않고 `기억해야/잊어도 될 정보를 따로 계산`\n",
    "- 핵심은 $C$라는 `장기기억셀`을 사용하는 것으로 `LSTM 계층 내에서만 전달`되며 과거부터 $t$까지 모든 정보 저장하고 곱셈 외 덧셈을 반영하여  `역전파시 기울기 소실 문제가 해결`\n",
    "- `곱하기 이외에 더하기를 사용`하였고, 두개 가중치($C$:long-term & $H$:short-term)의 `가중평균`\n",
    "\n",
    "<center><img src='Image/Expert/DL_RNN_Operation.png' width='700'>(http://colah.github.io/posts/2015-08-Understanding-LSTMs/)</center>\n",
    "\n",
    "**(0) 게이트(Gate):** `데이터의 흐름을 제어하는 문`의 개념으로 RNN과 달리 `3개의 입력값`을 사용\n",
    "\n",
    "- $X_t, H_{t-1}$는 각각 `1) 현재의 입력과 2) 과거의 단기정보`를 의미\n",
    "- $C_t$는 `3) 과거의 장기정보`를 제어하며,\n",
    "$$C_t = F_t*C_{t-1} + I_t*G_t$$\n",
    "> - 어제까지의 데이터를 얼마나 잊을지 $\\rightarrow$ $F_t$\n",
    "> - $F_t$가 0이면 과거의 영향 미고려 & 1이면 과거의 영향이 상당한 의미\n",
    "> - 현재에서의 새로운정보($G_t$)를 얼마나 반영할지($I_t$)를 통해 `실질적 업데이트`\n",
    "\n",
    "<span style=\"color:red\">$\\rightarrow$ **\"기존의 정보를 얼만큼 잊고, 새로운 정보로 얼만큼 반영 할 것인가?\"**</span>\n",
    "\n",
    "**(1) 망각게이트(Forget Gate):** `과거(장기)를 얼마나 잊을지` 제어하기 위한 가중치\n",
    "\n",
    "- **sigmoid:** 정보가 `0과 1사이에서 얼마나 통과`시킬지 결정\n",
    "\n",
    "$$F_t = sigmoid(U_F H_{t-1} + W_F X_t)$$\n",
    "\n",
    "<span style=\"color:red\">$\\rightarrow$ **\"기존의 정보를 얼마나 잊어버릴 것인가?\"**</span>\n",
    "\n",
    "**(2-1) 새로운입력(Input Candidate):** RNN 은닉층처럼 `새로운 정보 추출`\n",
    "\n",
    "- **tanh:** `RNN의 활성화 함수`로 relu로 대체될 수도 있음\n",
    "\n",
    "$$G_t = tanh(U_G H_{t-1} + W_G X_t)$$\n",
    "\n",
    "**(2-2) 입력게이트(Input Gate):** `새로운 정보의 가치`를 판단하여 `장기예측에 도움될지 추정`\n",
    "\n",
    "$$I_t = sigmoid(U_I H_{t-1} + W_I X_t)$$\n",
    "\n",
    "<span style=\"color:red\">$\\rightarrow$ **\"새로운 정보를 얼마나 기억할 것인가?\"**</span>\n",
    "\n",
    "**(3) 출력게이트(Output Gate):**  `1) 현재입력, 2) 과거단기, 3) 과거장기 정보를 반영`함과 동시에 `미래 시점의 예측값`으로 출력\n",
    "\n",
    "$$C_t = F_t*C_{t-1} + I_t*G_t \\\\ O_t = sigmoid(U_O H_{t-1} + W_O X_t)$$\n",
    "\n",
    "$$H_t = O_t * tanh(C_t) \\\\ Y_t = f(H_t) = softmax(VH_t)$$\n",
    " \n",
    "<span style=\"color:red\">$\\rightarrow$ **\"`3) 과거 장기정보`($C_{t-1}$)는 필터링되고 현재의 새로운입력과 과거 단기정보가 추가되어 업데이트 되며($C_t$), `1) 현재입력, 2) 과거단기`와 결합되어 `새로운 단기 예측값`($H_t, Y_t$)을 출력\"**</span>\n",
    "\n",
    "- 입출력이 복잡해 보이지만 `수학/행렬적 연산은 심플`\n",
    "\n",
    "<center><img src='Image/Expert/LSTM_Summary.PNG' width='700'>(http://cs231n.stanford.edu/)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated Recurrent Unit\n",
    "\n",
    "> **\"`RNN의 장기기억문제 해결책`으로 고안되었고, Gate 구조가 적용된 LSTM에서 영감을 받아 `간결한 구조를 채택하여 계산상 효율적이고 유사한 성능`(Cho et al. 2014)\"**\n",
    ">\n",
    "> - LSTM이 Sequence 데이터 특화라면 `GRU는 자연어 데이터 특화 모델로 LSTM의 간소화 버전`\n",
    "> - LSTM은 Gate가 3개지만 `GRU는 Gate가 2개` (Reset Gate & Update Gate(Forget+Input 유사))\n",
    ">> - Convex 조합을 수행하는 두개의 벡터라고 볼 수 있음 (0 or 1)   \n",
    "> - Output Gate가 없는 LSTM이기에 메모리셀에 담기는 정보 양 증가\n",
    "> - LSTM의 $C_t$와 $H_t$가 Cell State를 대신하는 하나의 벡터 $H_t$로 통합\n",
    "> - GRU가 LSTM보다 학습할 가중치가 적은 이점\n",
    "> - 주제별로 LSTM과 GRU의 성능은 차이\n",
    ">\n",
    "> <center><img src='Image/Expert/DL_LSTM_GRU.png' width='700'>(https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/Expert/DL_GRU_Architecture.png' width='350'></center>\n",
    "\n",
    "**(1) 초기화게이트(Reset Gate):** `과거의 데이터를 어느 정도의 비율로 제거`할지 결정\n",
    "\n",
    "$$R_t = sigmoid (U_R H_{t-1} + W_R X_t)$$\n",
    "\n",
    "**(2-1) 업데이트게이트(Update Gate):** `현재의 데이터를 얼마나 반영`할지 결정(`Input층과 유사`)\n",
    "\n",
    "$$U_t = sigmoid (U_U H_{t-1} + W_U X_t)$$\n",
    "\n",
    "**(2-2) 업데이트게이트(Update Gate):** `현재에 잊어버려야 할 과거의 데이터 비율` 결정(`Forget층과 유사`)\n",
    "\n",
    "$$1 - U_t$$\n",
    "\n",
    "- Update Gate($U_t$)로 `LSTM의 Forget과 Input 게이트를 모두 제어`\n",
    "- 즉, $t-1$의 기억과 $t$의 `기억중 하나만 선택`\n",
    "\n",
    "**(3) 새로운입력(Input Candidate):** 과거를 그대로 사용하지 않고 `리셋 데이터`로 `장기예측에 도움될 새로운 정보 출력`   \n",
    "\n",
    "- $H_t$가 각 시점마다 출력되며 $H_{t-1}$의 `어느정도 비율을 출력할지 제어`하는 $R_t$\n",
    "\n",
    "$$h_t = tanh (U_h H_{t-1}*R_t + W_h X_t)$$\n",
    "\n",
    "**(4) 은닉층(Output) :** 출력층이 따로없지만 `Update와 Candidate 결합`하여 `미래 시점의 예측값으로 출력`\n",
    "\n",
    "$$H_t = (1 - U_t)*H_{t-1} + U_t*h_t$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/Expert/CNN_RNN_MLP_SVM.PNG' width='800'></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## AutoEncoder -->"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1179.32px",
    "left": "29px",
    "top": "151px",
    "width": "391.75px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
